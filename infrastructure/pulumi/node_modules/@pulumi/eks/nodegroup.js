"use strict";
// Copyright 2016-2022, Pulumi Corporation.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.getArchitecture = exports.isGravitonInstance = exports.createManagedNodeGroup = exports.ManagedNodeGroupInternal = exports.ManagedNodeGroup = exports.computeWorkerSubnets = exports.createNodeGroupV2 = exports.createNodeGroup = exports.NodeGroupV2Internal = exports.NodeGroupV2 = exports.NodeGroupInternal = exports.NodeGroup = void 0;
const aws = require("@pulumi/aws");
const pulumi = require("@pulumi/pulumi");
const netmask = require("netmask");
const authenticationMode_1 = require("./authenticationMode");
const cluster_1 = require("./cluster");
const randomSuffix_1 = require("./randomSuffix");
const securitygroup_1 = require("./securitygroup");
/**
 * NodeGroup is a component that wraps the AWS EC2 instances that provide compute capacity for an EKS cluster.
 */
class NodeGroup extends pulumi.ComponentResource {
    /**
     * Create a new EKS cluster with worker nodes, optional storage classes, and deploy the Kubernetes Dashboard if
     * requested.
     *
     * @param name The _unique_ name of this component.
     * @param args The arguments for this cluster.
     * @param opts A bag of options that control this component's behavior.
     */
    constructor(name, args, opts) {
        super("eks:index:NodeGroup", name, args, opts);
        const group = createNodeGroup(name, args, this, opts === null || opts === void 0 ? void 0 : opts.provider);
        this.nodeSecurityGroup = group.nodeSecurityGroup;
        this.cfnStack = group.cfnStack;
        this.autoScalingGroupName = group.autoScalingGroupName;
        this.registerOutputs(undefined);
    }
}
exports.NodeGroup = NodeGroup;
/**
 * This is a variant of `NodeGroup` that is used for the MLC `NodeGroup`. We don't just use `NodeGroup`,
 * because we need to accept `ClusterInternal` as the `cluster` arg, so we can correctly pull out `cluster.core`
 * for use in creating the `NodeGroup`.
 *
 * @internal
 */
class NodeGroupInternal extends pulumi.ComponentResource {
    constructor(name, args, opts) {
        var _a;
        const type = "eks:index:NodeGroup";
        if (opts === null || opts === void 0 ? void 0 : opts.urn) {
            const props = {
                autoScalingGroupName: undefined,
                cfnStack: undefined,
                extraNodeSecurityGroups: undefined,
                nodeSecurityGroup: undefined,
            };
            super(type, name, props, opts);
            return;
        }
        super(type, name, args, opts);
        const core = pulumi
            .output(args.cluster)
            .apply((c) => (c instanceof cluster_1.ClusterInternal ? c.core : c));
        const group = createNodeGroupInternal(name, args, core, this, opts === null || opts === void 0 ? void 0 : opts.provider);
        this.autoScalingGroupName = group.autoScalingGroupName;
        this.cfnStack = pulumi.output(group.cfnStack);
        this.extraNodeSecurityGroups = pulumi.output((_a = group.extraNodeSecurityGroups) !== null && _a !== void 0 ? _a : []);
        this.nodeSecurityGroup = pulumi.output(group.nodeSecurityGroup);
        this.registerOutputs({
            autoScalingGroupName: this.autoScalingGroupName,
            cfnStack: this.cfnStack,
            extraNodeSecurityGroups: this.extraNodeSecurityGroups,
            nodeSecurityGroup: this.nodeSecurityGroup,
        });
    }
}
exports.NodeGroupInternal = NodeGroupInternal;
class NodeGroupV2 extends pulumi.ComponentResource {
    /**
     * Create a new EKS cluster with worker nodes, optional storage classes, and deploy the Kubernetes Dashboard if
     * requested.
     *
     * @param name The _unique_ name of this component.
     * @param args The arguments for this cluster.
     * @param opts A bag of options that control this component's behavior.
     */
    constructor(name, args, opts) {
        super("eks:index:NodeGroupV2", name, args, opts);
        const group = createNodeGroupV2(name, args, this, opts === null || opts === void 0 ? void 0 : opts.provider);
        this.nodeSecurityGroup = group.nodeSecurityGroup;
        this.autoScalingGroup = group.autoScalingGroup;
        this.registerOutputs(undefined);
    }
}
exports.NodeGroupV2 = NodeGroupV2;
/**
 * This is a variant of `NodeGroupV2` that is used for the MLC `NodeGroupV2`. We don't just use `NodeGroupV2`,
 * because we need to accept `ClusterInternal` as the `cluster` arg, so we can correctly pull out `cluster.core`
 * for use in creating the `NodeGroupV2`.
 *
 * @internal
 */
class NodeGroupV2Internal extends pulumi.ComponentResource {
    constructor(name, args, opts) {
        var _a;
        const type = "eks:index:NodeGroupV2";
        if (opts === null || opts === void 0 ? void 0 : opts.urn) {
            const props = {
                autoScalingGroup: undefined,
                extraNodeSecurityGroups: undefined,
                nodeSecurityGroup: undefined,
            };
            super(type, name, props, opts);
            return;
        }
        super(type, name, args, opts);
        const core = pulumi
            .output(args.cluster)
            .apply((c) => (c instanceof cluster_1.ClusterInternal ? c.core : c));
        const group = createNodeGroupV2Internal(name, args, core, this, opts === null || opts === void 0 ? void 0 : opts.provider);
        this.autoScalingGroup = pulumi.output(group.autoScalingGroup);
        this.extraNodeSecurityGroups = pulumi.output((_a = group.extraNodeSecurityGroups) !== null && _a !== void 0 ? _a : []);
        this.nodeSecurityGroup = pulumi.output(group.nodeSecurityGroup);
        this.registerOutputs({
            autoScalingGroup: this.autoScalingGroup,
            extraNodeSecurityGroups: this.extraNodeSecurityGroups,
            nodeSecurityGroup: this.nodeSecurityGroup,
        });
    }
}
exports.NodeGroupV2Internal = NodeGroupV2Internal;
/**
 * Create a self-managed node group using CloudFormation and an ASG.
 *
 * See for more details:
 * https://docs.aws.amazon.com/eks/latest/userguide/worker.html
 */
function createNodeGroup(name, args, parent, provider) {
    const core = args.cluster instanceof cluster_1.Cluster ? args.cluster.core : args.cluster;
    return createNodeGroupInternal(name, args, pulumi.output(core), parent, provider);
}
exports.createNodeGroup = createNodeGroup;
function createNodeGroupInternal(name, args, core, parent, provider) {
    var _a, _b, _c, _d;
    const instanceProfile = core.apply((c) => {
        var _a;
        if (!args.instanceProfile && !c.nodeGroupOptions.instanceProfile) {
            throw new pulumi.ResourceError(`an instanceProfile is required`, parent);
        }
        return (_a = args.instanceProfile) !== null && _a !== void 0 ? _a : c.nodeGroupOptions.instanceProfile;
    });
    core.apply((c) => {
        if (c.nodeGroupOptions.nodeSecurityGroup && args.nodeSecurityGroup) {
            if (c.nodeSecurityGroupTags &&
                c.nodeGroupOptions.nodeSecurityGroup.id !== args.nodeSecurityGroup.id) {
                throw new pulumi.ResourceError(`The NodeGroup's nodeSecurityGroup and the cluster option nodeSecurityGroupTags are mutually exclusive. Choose a single approach`, parent);
            }
        }
    });
    if (args.nodePublicKey && args.keyName) {
        throw new pulumi.ResourceError("nodePublicKey and keyName are mutually exclusive. Choose a single approach", parent);
    }
    if (args.amiId && args.gpu) {
        throw new pulumi.ResourceError("amiId and gpu are mutually exclusive.", parent);
    }
    if (args.nodeUserDataOverride &&
        (args.nodeUserData ||
            args.labels ||
            args.taints ||
            args.kubeletExtraArgs ||
            args.bootstrapExtraArgs)) {
        throw new pulumi.ResourceError("nodeUserDataOverride and any combination of {nodeUserData, labels, taints, kubeletExtraArgs, or bootstrapExtraArgs} is mutually exclusive.", parent);
    }
    let nodeSecurityGroup;
    const eksCluster = core.cluster;
    const cfnStackDeps = core.apply((c) => {
        const result = [];
        if (c.vpcCni !== undefined) {
            result.push(c.vpcCni);
        }
        if (c.eksNodeAccess !== undefined) {
            result.push(c.eksNodeAccess);
        }
        return result;
    });
    let eksClusterIngressRule = args.clusterIngressRule;
    if (args.nodeSecurityGroup) {
        nodeSecurityGroup = args.nodeSecurityGroup;
        if (eksClusterIngressRule === undefined) {
            throw new pulumi.ResourceError(`invalid args for node group ${name}, clusterIngressRule is required when nodeSecurityGroup is manually specified`, parent);
        }
    }
    else {
        [nodeSecurityGroup, eksClusterIngressRule] = (0, securitygroup_1.createNodeGroupSecurityGroup)(name, {
            vpcId: core.vpcId,
            clusterSecurityGroup: core.clusterSecurityGroup,
            eksCluster: eksCluster,
            tags: pulumi.all([core.tags, core.nodeSecurityGroupTags]).apply(([tags, nodeSecurityGroupTags]) => (Object.assign(Object.assign({}, nodeSecurityGroupTags), tags))),
        }, parent);
    }
    // This apply is necessary in s.t. the launchConfiguration picks up a
    // dependency on the eksClusterIngressRule. The nodes may fail to
    // connect to the cluster if we attempt to create them before the
    // ingress rule is applied.
    const nodeSecurityGroupId = pulumi
        .all([nodeSecurityGroup.id, eksClusterIngressRule.id])
        .apply(([id]) => id);
    // Collect the IDs of any extra, user-specific security groups.
    const extraSGOutput = pulumi.output(args.extraNodeSecurityGroups);
    const extraNodeSecurityGroupIds = pulumi.all([extraSGOutput]).apply(([sg]) => {
        if (sg === undefined) {
            return [];
        }
        // Map out the ARNs of all of the instanceRoles.
        return sg.map((sg) => sg.id);
    });
    // If requested, add a new EC2 KeyPair for SSH access to the instances.
    let keyName = args.keyName;
    if (args.nodePublicKey) {
        const key = new aws.ec2.KeyPair(`${name}-keyPair`, {
            publicKey: args.nodePublicKey,
        }, { parent, provider });
        keyName = key.keyName;
    }
    const cfnStackName = (0, randomSuffix_1.default)(`${name}-cfnStackName`, name, { parent });
    const awsRegion = pulumi.output(aws.getRegion({}, { parent, async: true }));
    const userDataArg = args.nodeUserData || pulumi.output("");
    const kubeletExtraArgs = args.kubeletExtraArgs ? args.kubeletExtraArgs.split(" ") : [];
    if (args.labels) {
        const parts = [];
        for (const key of Object.keys(args.labels)) {
            parts.push(key + "=" + args.labels[key]);
        }
        if (parts.length > 0) {
            kubeletExtraArgs.push("--node-labels=" + parts.join(","));
        }
    }
    if (args.taints) {
        const parts = [];
        for (const key of Object.keys(args.taints)) {
            const taint = args.taints[key];
            parts.push(key + "=" + taint.value + ":" + taint.effect);
        }
        if (parts.length > 0) {
            kubeletExtraArgs.push("--register-with-taints=" + parts.join(","));
        }
    }
    let bootstrapExtraArgs = args.bootstrapExtraArgs ? " " + args.bootstrapExtraArgs : "";
    if (kubeletExtraArgs.length === 1) {
        // For backward compatibility with previous versions of this package, don't wrap a single argument with `''`.
        bootstrapExtraArgs += ` --kubelet-extra-args ${kubeletExtraArgs[0]}`;
    }
    else if (kubeletExtraArgs.length > 1) {
        bootstrapExtraArgs += ` --kubelet-extra-args '${kubeletExtraArgs.join(" ")}'`;
    }
    const userdata = pulumi
        .all([
        awsRegion,
        eksCluster.name,
        eksCluster.endpoint,
        eksCluster.certificateAuthority,
        cfnStackName,
        userDataArg,
    ])
        .apply(([region, clusterName, clusterEndpoint, clusterCa, stackName, customUserData]) => {
        if (customUserData !== "") {
            customUserData = `cat >/opt/user-data <<${stackName}-user-data
${customUserData}
${stackName}-user-data
chmod +x /opt/user-data
/opt/user-data
`;
        }
        return `#!/bin/bash

/etc/eks/bootstrap.sh --apiserver-endpoint "${clusterEndpoint}" --b64-cluster-ca "${clusterCa.data}" "${clusterName}"${bootstrapExtraArgs}
${customUserData}
/opt/aws/bin/cfn-signal --exit-code $? --stack ${stackName} --resource NodeGroup --region ${region.name}
`;
    });
    const version = pulumi.output(args.version || core.cluster.version);
    const amiId = args.amiId || getRecommendedAMI(args, version, parent);
    // Enable auto-assignment of public IP addresses on worker nodes for
    // backwards compatibility on existing EKS clusters launched with it
    // enabled. Defaults to `true`.
    let nodeAssociatePublicIpAddress = true;
    if (args.nodeAssociatePublicIpAddress !== undefined) {
        nodeAssociatePublicIpAddress = args.nodeAssociatePublicIpAddress;
    }
    const numeric = new RegExp("^\\d+$");
    // We need to wrap the validation in a pulumi.all as MLCs could supply pulumi.Output<T> or T.
    pulumi
        .all([args.nodeRootVolumeIops, args.nodeRootVolumeType, args.nodeRootVolumeThroughput])
        .apply(([nodeRootVolumeIops, nodeRootVolumeType, nodeRootVolumeThroughput]) => {
        if (nodeRootVolumeIops && nodeRootVolumeType !== "io1") {
            throw new pulumi.ResourceError("Cannot create a cluster node root volume of non-io1 type with provisioned IOPS (nodeRootVolumeIops).", parent);
        }
        if (nodeRootVolumeType === "io1" && nodeRootVolumeIops) {
            if (!numeric.test(nodeRootVolumeIops === null || nodeRootVolumeIops === void 0 ? void 0 : nodeRootVolumeIops.toString())) {
                throw new pulumi.ResourceError("Cannot create a cluster node root volume of io1 type without provisioned IOPS (nodeRootVolumeIops) as integer value.", parent);
            }
        }
        if (nodeRootVolumeThroughput && nodeRootVolumeType !== "gp3") {
            throw new pulumi.ResourceError("Cannot create a cluster node root volume of non-gp3 type with provisioned throughput (nodeRootVolumeThroughput).", parent);
        }
        if (nodeRootVolumeType === "gp3" && nodeRootVolumeThroughput) {
            if (!numeric.test(nodeRootVolumeThroughput === null || nodeRootVolumeThroughput === void 0 ? void 0 : nodeRootVolumeThroughput.toString())) {
                throw new pulumi.ResourceError("Cannot create a cluster node root volume of gp3 type without provisioned throughput (nodeRootVolumeThroughput) as integer value.", parent);
            }
        }
    });
    const nodeLaunchConfiguration = new aws.ec2.LaunchConfiguration(`${name}-nodeLaunchConfiguration`, {
        associatePublicIpAddress: nodeAssociatePublicIpAddress,
        imageId: amiId,
        instanceType: args.instanceType || "t2.medium",
        iamInstanceProfile: instanceProfile,
        keyName: keyName,
        securityGroups: pulumi
            .all([nodeSecurityGroupId, extraNodeSecurityGroupIds])
            .apply(([sg, extraSG]) => [sg, ...extraSG]),
        spotPrice: args.spotPrice,
        rootBlockDevice: {
            encrypted: (_a = args.nodeRootVolumeEncrypted) !== null && _a !== void 0 ? _a : false,
            volumeSize: (_b = args.nodeRootVolumeSize) !== null && _b !== void 0 ? _b : 20,
            volumeType: (_c = args.nodeRootVolumeType) !== null && _c !== void 0 ? _c : "gp2",
            iops: args.nodeRootVolumeIops,
            throughput: args.nodeRootVolumeThroughput,
            deleteOnTermination: (_d = args.nodeRootVolumeDeleteOnTermination) !== null && _d !== void 0 ? _d : true,
        },
        userData: args.nodeUserDataOverride || userdata,
        enableMonitoring: args.enableDetailedMonitoring,
    }, { parent, provider });
    // Compute the worker node group subnets to use from the various approaches.
    let workerSubnetIds;
    if (args.nodeSubnetIds !== undefined) {
        // Use the specified override subnetIds.
        workerSubnetIds = pulumi.output(args.nodeSubnetIds);
    }
    else {
        workerSubnetIds = core.apply((c) => {
            if (c.privateSubnetIds !== undefined) {
                // Use the specified private subnetIds.
                return Promise.resolve(c.privateSubnetIds);
            }
            else if (c.publicSubnetIds !== undefined) {
                // Use the specified public subnetIds.
                return Promise.resolve(c.publicSubnetIds);
            }
            else {
                // Use subnetIds from the cluster. Compute / auto-discover the private worker subnetIds from this set.
                return computeWorkerSubnets(parent, c.subnetIds);
            }
        });
    }
    // Configure the settings for the autoscaling group.
    if (args.desiredCapacity === undefined) {
        args.desiredCapacity = 2;
    }
    if (args.minSize === undefined) {
        args.minSize = 1;
    }
    if (args.maxSize === undefined) {
        args.maxSize = 2;
    }
    let minInstancesInService = 1;
    if (args.spotPrice) {
        minInstancesInService = 0;
    }
    const autoScalingGroupTags = pulumi
        .all([eksCluster.name, args.autoScalingGroupTags])
        .apply(([clusterName, asgTags]) => (Object.assign({ Name: `${clusterName}-worker`, [`kubernetes.io/cluster/${clusterName}`]: "owned" }, asgTags)));
    const cfnTemplateBody = pulumi
        .all([
        nodeLaunchConfiguration.id,
        args.desiredCapacity,
        args.minSize,
        args.maxSize,
        tagsToAsgTags(autoScalingGroupTags),
        workerSubnetIds.apply(JSON.stringify),
    ])
        .apply(([launchConfig, desiredCapacity, minSize, maxSize, asgTags, vpcSubnetIds]) => `
                AWSTemplateFormatVersion: '2010-09-09'
                Outputs:
                    NodeGroup:
                        Value: !Ref NodeGroup
                Resources:
                    NodeGroup:
                        Type: AWS::AutoScaling::AutoScalingGroup
                        Properties:
                          DesiredCapacity: ${desiredCapacity}
                          LaunchConfigurationName: ${launchConfig}
                          MinSize: ${minSize}
                          MaxSize: ${maxSize}
                          VPCZoneIdentifier: ${vpcSubnetIds}
                          Tags:
                          ${asgTags}
                        UpdatePolicy:
                          AutoScalingRollingUpdate:
                            MinInstancesInService: '${minInstancesInService}'
                            MaxBatchSize: '1'
                `);
    const cfnStack = new aws.cloudformation.Stack(`${name}-nodes`, {
        name: cfnStackName,
        templateBody: cfnTemplateBody,
        tags: pulumi.all([core.tags, args.cloudFormationTags]).apply(([tags, cloudFormationTags]) => (Object.assign(Object.assign({ Name: `${name}-nodes` }, cloudFormationTags), tags))),
    }, { parent, dependsOn: cfnStackDeps, provider });
    const autoScalingGroupName = cfnStack.outputs.apply((outputs) => {
        if (!("NodeGroup" in outputs)) {
            throw new pulumi.ResourceError("CloudFormation stack is not ready. Stack output key 'NodeGroup' does not exist.", parent);
        }
        return outputs["NodeGroup"];
    });
    return {
        nodeSecurityGroup: nodeSecurityGroup,
        cfnStack: cfnStack,
        autoScalingGroupName: autoScalingGroupName,
        extraNodeSecurityGroups: args.extraNodeSecurityGroups,
    };
}
/**
 * Create a self-managed node group using a Launch Template and an ASG.
 *
 * See for more details:
 * https://docs.aws.amazon.com/eks/latest/userguide/worker.html
 */
function createNodeGroupV2(name, args, parent, provider) {
    const core = args.cluster instanceof cluster_1.Cluster ? args.cluster.core : args.cluster;
    return createNodeGroupV2Internal(name, args, pulumi.output(core), parent, provider);
}
exports.createNodeGroupV2 = createNodeGroupV2;
function createNodeGroupV2Internal(name, args, core, parent, provider) {
    var _a, _b, _c, _d, _e, _f, _g, _h;
    const instanceProfileArn = core.apply((c) => {
        var _a, _b;
        if (!args.instanceProfile && !c.nodeGroupOptions.instanceProfile) {
            throw new pulumi.ResourceError(`an instanceProfile is required`, parent);
        }
        return (_b = (_a = args.instanceProfile) === null || _a === void 0 ? void 0 : _a.arn) !== null && _b !== void 0 ? _b : c.nodeGroupOptions.instanceProfile.arn;
    });
    core.apply((c) => {
        if (c.nodeGroupOptions.nodeSecurityGroup && args.nodeSecurityGroup) {
            if (c.nodeSecurityGroupTags &&
                c.nodeGroupOptions.nodeSecurityGroup.id !== args.nodeSecurityGroup.id) {
                throw new pulumi.ResourceError(`The NodeGroup's nodeSecurityGroup and the cluster option nodeSecurityGroupTags are mutually exclusive. Choose a single approach`, parent);
            }
        }
    });
    if (args.nodePublicKey && args.keyName) {
        throw new pulumi.ResourceError("nodePublicKey and keyName are mutually exclusive. Choose a single approach", parent);
    }
    if (args.amiId && args.gpu) {
        throw new pulumi.ResourceError("amiId and gpu are mutually exclusive.", parent);
    }
    if (args.nodeUserDataOverride &&
        (args.nodeUserData ||
            args.labels ||
            args.taints ||
            args.kubeletExtraArgs ||
            args.bootstrapExtraArgs)) {
        throw new pulumi.ResourceError("nodeUserDataOverride and any combination of {nodeUserData, labels, taints, kubeletExtraArgs, or bootstrapExtraArgs} is mutually exclusive.", parent);
    }
    let nodeSecurityGroup;
    const eksCluster = core.cluster;
    const nodeGroupDeps = core.apply((c) => {
        const result = [];
        if (c.vpcCni !== undefined) {
            result.push(c.vpcCni);
        }
        if (c.eksNodeAccess !== undefined) {
            result.push(c.eksNodeAccess);
        }
        return result;
    });
    let eksClusterIngressRule = args.clusterIngressRule;
    if (args.nodeSecurityGroup) {
        nodeSecurityGroup = args.nodeSecurityGroup;
        if (eksClusterIngressRule === undefined) {
            throw new pulumi.ResourceError(`invalid args for node group ${name}, clusterIngressRule is required when nodeSecurityGroup is manually specified`, parent);
        }
    }
    else {
        [nodeSecurityGroup, eksClusterIngressRule] = (0, securitygroup_1.createNodeGroupSecurityGroup)(name, {
            vpcId: core.vpcId,
            clusterSecurityGroup: core.clusterSecurityGroup,
            eksCluster: eksCluster,
            tags: core.apply((c) => (Object.assign(Object.assign({}, c.nodeSecurityGroupTags), c.tags))),
        }, parent);
    }
    // This apply is necessary in s.t. the launchConfiguration picks up a
    // dependency on the eksClusterIngressRule. The nodes may fail to
    // connect to the cluster if we attempt to create them before the
    // ingress rule is applied.
    const nodeSecurityGroupId = pulumi
        .all([nodeSecurityGroup.id, eksClusterIngressRule.id])
        .apply(([id]) => id);
    // Collect the IDs of any extra, user-specific security groups.
    const extraNodeSecurityGroupIds = pulumi.all([args.extraNodeSecurityGroups]).apply(([sg]) => {
        if (sg === undefined) {
            return [];
        }
        // Map out the ARNs of all of the instanceRoles.
        return sg.map((sg) => sg.id);
    });
    // If requested, add a new EC2 KeyPair for SSH access to the instances.
    let keyName = args.keyName;
    if (args.nodePublicKey) {
        const key = new aws.ec2.KeyPair(`${name}-keyPair`, {
            publicKey: args.nodePublicKey,
        }, { parent, provider });
        keyName = key.keyName;
    }
    const awsRegion = pulumi.output(aws.getRegion({}, { parent, async: true }));
    const userDataArg = args.nodeUserData || pulumi.output("");
    const kubeletExtraArgs = args.kubeletExtraArgs ? args.kubeletExtraArgs.split(" ") : [];
    if (args.labels) {
        const parts = [];
        for (const key of Object.keys(args.labels)) {
            parts.push(key + "=" + args.labels[key]);
        }
        if (parts.length > 0) {
            kubeletExtraArgs.push("--node-labels=" + parts.join(","));
        }
    }
    if (args.taints) {
        const parts = [];
        for (const key of Object.keys(args.taints)) {
            const taint = args.taints[key];
            parts.push(key + "=" + taint.value + ":" + taint.effect);
        }
        if (parts.length > 0) {
            kubeletExtraArgs.push("--register-with-taints=" + parts.join(","));
        }
    }
    let bootstrapExtraArgs = args.bootstrapExtraArgs ? " " + args.bootstrapExtraArgs : "";
    if (kubeletExtraArgs.length === 1) {
        // For backward compatibility with previous versions of this package, don't wrap a single argument with `''`.
        bootstrapExtraArgs += ` --kubelet-extra-args ${kubeletExtraArgs[0]}`;
    }
    else if (kubeletExtraArgs.length > 1) {
        bootstrapExtraArgs += ` --kubelet-extra-args '${kubeletExtraArgs.join(" ")}'`;
    }
    const userdata = pulumi
        .all([
        awsRegion,
        eksCluster.name,
        eksCluster.endpoint,
        eksCluster.certificateAuthority,
        name,
        userDataArg,
        args.nodeUserDataOverride,
    ])
        .apply(([region, clusterName, clusterEndpoint, clusterCa, stackName, customUserData, nodeUserDataOverride,]) => {
        if (nodeUserDataOverride !== undefined && nodeUserDataOverride !== "") {
            return nodeUserDataOverride;
        }
        if (customUserData !== "") {
            customUserData = `cat >/opt/user-data <<${stackName}-user-data
${customUserData}
${stackName}-user-data
chmod +x /opt/user-data
/opt/user-data
`;
        }
        return `#!/bin/bash

/etc/eks/bootstrap.sh --apiserver-endpoint "${clusterEndpoint}" --b64-cluster-ca "${clusterCa.data}" "${clusterName}"${bootstrapExtraArgs}
${customUserData}
`;
    })
        .apply((x) => Buffer.from(x, "utf-8").toString("base64")); // Launch Templates require user data to be passed as base64.
    const version = pulumi.output(args.version || core.cluster.version);
    const amiId = args.amiId || getRecommendedAMI(args, version, parent);
    // Enable auto-assignment of public IP addresses on worker nodes for
    // backwards compatibility on existing EKS clusters launched with it
    // enabled. Defaults to `true`.
    let nodeAssociatePublicIpAddress = true;
    if (args.nodeAssociatePublicIpAddress !== undefined) {
        nodeAssociatePublicIpAddress = args.nodeAssociatePublicIpAddress;
    }
    const numeric = new RegExp("^\\d+$");
    // We need to wrap the validation in a pulumi.all as MLCs could supply pulumi.Output<T> or T.
    pulumi
        .all([args.nodeRootVolumeIops, args.nodeRootVolumeType, args.nodeRootVolumeThroughput])
        .apply(([nodeRootVolumeIops, nodeRootVolumeType, nodeRootVolumeThroughput]) => {
        if (nodeRootVolumeIops && nodeRootVolumeType !== "io1") {
            throw new pulumi.ResourceError("Cannot create a cluster node root volume of non-io1 type with provisioned IOPS (nodeRootVolumeIops).", parent);
        }
        if (nodeRootVolumeType === "io1" && nodeRootVolumeIops) {
            if (!numeric.test(nodeRootVolumeIops === null || nodeRootVolumeIops === void 0 ? void 0 : nodeRootVolumeIops.toString())) {
                throw new pulumi.ResourceError("Cannot create a cluster node root volume of io1 type without provisioned IOPS (nodeRootVolumeIops) as integer value.", parent);
            }
        }
        if (nodeRootVolumeThroughput && nodeRootVolumeType !== "gp3") {
            throw new pulumi.ResourceError("Cannot create a cluster node root volume of non-gp3 type with provisioned throughput (nodeRootVolumeThroughput).", parent);
        }
        if (nodeRootVolumeType === "gp3" && nodeRootVolumeThroughput) {
            if (!numeric.test(nodeRootVolumeThroughput === null || nodeRootVolumeThroughput === void 0 ? void 0 : nodeRootVolumeThroughput.toString())) {
                throw new pulumi.ResourceError("Cannot create a cluster node root volume of gp3 type without provisioned throughput (nodeRootVolumeThroughput) as integer value.", parent);
            }
        }
    });
    const marketOptions = args.spotPrice
        ? {
            marketType: "spot",
            spotOptions: {
                maxPrice: args.spotPrice,
            },
        }
        : undefined;
    const device = pulumi.output(amiId).apply((id) => aws.ec2.getAmi({
        owners: ["self", "amazon"],
        filters: [
            {
                name: "image-id",
                values: [id],
            },
        ],
    }, { parent })).blockDeviceMappings[0].deviceName;
    const nodeLaunchTemplate = new aws.ec2.LaunchTemplate(`${name}-launchTemplate`, {
        imageId: amiId,
        instanceType: args.instanceType || "t2.medium",
        iamInstanceProfile: { arn: instanceProfileArn },
        keyName: keyName,
        instanceMarketOptions: marketOptions,
        blockDeviceMappings: [
            {
                deviceName: device,
                ebs: {
                    encrypted: ((_a = args.nodeRootVolumeEncrypted) !== null && _a !== void 0 ? _a : false) ? "true" : "false",
                    volumeSize: (_b = args.nodeRootVolumeSize) !== null && _b !== void 0 ? _b : 20,
                    volumeType: (_c = args.nodeRootVolumeType) !== null && _c !== void 0 ? _c : "gp2",
                    iops: args.nodeRootVolumeIops,
                    throughput: args.nodeRootVolumeThroughput,
                    deleteOnTermination: ((_d = args.nodeRootVolumeDeleteOnTermination) !== null && _d !== void 0 ? _d : true) ? "true" : "false",
                },
            },
        ],
        networkInterfaces: [
            {
                associatePublicIpAddress: String(nodeAssociatePublicIpAddress),
                securityGroups: pulumi
                    .all([nodeSecurityGroupId, extraNodeSecurityGroupIds])
                    .apply(([sg, extraSG]) => [sg, ...extraSG]),
            },
        ],
        metadataOptions: args.metadataOptions,
        userData: userdata,
        tagSpecifications: args.launchTemplateTagSpecifications,
        monitoring: args.enableDetailedMonitoring == null
            ? undefined
            : {
                enabled: args.enableDetailedMonitoring,
            },
    }, { parent, provider });
    // Compute the worker node group subnets to use from the various approaches.
    let workerSubnetIds;
    if (args.nodeSubnetIds !== undefined) {
        // Use the specified override subnetIds.
        workerSubnetIds = pulumi.output(args.nodeSubnetIds);
    }
    else {
        workerSubnetIds = core.apply((c) => {
            if (c.privateSubnetIds !== undefined) {
                // Use the specified private subnetIds.
                return Promise.resolve(c.privateSubnetIds);
            }
            else if (c.publicSubnetIds !== undefined) {
                // Use the specified public subnetIds.
                return Promise.resolve(c.publicSubnetIds);
            }
            else {
                // Use subnetIds from the cluster. Compute / auto-discover the private worker subnetIds from this set.
                return computeWorkerSubnets(parent, c.subnetIds);
            }
        });
    }
    const asgTags = pulumi
        .all([eksCluster.name, args.autoScalingGroupTags])
        .apply(([clusterName, tags]) => inputTagsToASGTags(clusterName, tags));
    const launchTemplateVersion = nodeLaunchTemplate.latestVersion.apply((v) => v.toString());
    const asGroup = new aws.autoscaling.Group(name, {
        minSize: (_e = args === null || args === void 0 ? void 0 : args.minSize) !== null && _e !== void 0 ? _e : 1,
        maxSize: (_f = args === null || args === void 0 ? void 0 : args.maxSize) !== null && _f !== void 0 ? _f : 2,
        desiredCapacity: (_g = args === null || args === void 0 ? void 0 : args.desiredCapacity) !== null && _g !== void 0 ? _g : 2,
        launchTemplate: {
            name: nodeLaunchTemplate.name,
            version: launchTemplateVersion,
        },
        vpcZoneIdentifiers: workerSubnetIds,
        instanceRefresh: {
            strategy: "Rolling",
            preferences: {
                minHealthyPercentage: (_h = args.minRefreshPercentage) !== null && _h !== void 0 ? _h : 50,
            },
        },
        tags: asgTags,
        defaultInstanceWarmup: args.defaultInstanceWarmup,
    }, { parent, dependsOn: nodeGroupDeps, provider });
    return {
        nodeSecurityGroup: nodeSecurityGroup,
        autoScalingGroup: asGroup,
        extraNodeSecurityGroups: args.extraNodeSecurityGroups,
    };
}
function inputTagsToASGTags(clusterName, tags) {
    const asgTags = Object.entries(tags !== null && tags !== void 0 ? tags : {}).map(([key, value]) => ({
        key,
        value,
        propagateAtLaunch: true,
    }));
    asgTags.push({
        value: "owned",
        key: "kubernetes.io/cluster/" + clusterName,
        propagateAtLaunch: true,
    }, {
        key: "Name",
        value: clusterName + "-worker",
        propagateAtLaunch: true,
    });
    return asgTags;
}
/** computeWorkerSubnets attempts to determine the subset of the given subnets to use for worker nodes.
 *
 * As per https://docs.aws.amazon.com/eks/latest/userguide/network_reqs.html, an EKS cluster that is attached to public
 * and private subnets will only expose its API service to workers on the private subnets. Any workers attached to the
 * public subnets will be unable to communicate with the API server.
 *
 * If all of the given subnet IDs are public, the list of subnet IDs is returned as-is. If any private subnet is given,
 * only the IDs of the private subnets are returned. A subnet is deemed private iff it has no route in its route table
 * that routes directly to an internet gateway. If any such route exists in a subnet's route table, it is treated as
 * public.
 */
function computeWorkerSubnets(parent, subnetIds) {
    return __awaiter(this, void 0, void 0, function* () {
        const publicSubnets = [];
        const privateSubnets = [];
        for (const subnetId of subnetIds) {
            // Fetch the route table for this subnet.
            const routeTable = yield getRouteTableAsync(parent, subnetId);
            // Once we have the route table, check its list of routes for a route to an internet gateway.
            const hasInternetGatewayRoute = routeTable.routes.find((r) => !!r.gatewayId && !isPrivateCIDRBlock(r.cidrBlock)) !==
                undefined;
            if (hasInternetGatewayRoute) {
                publicSubnets.push(subnetId);
            }
            else {
                privateSubnets.push(subnetId);
            }
        }
        return privateSubnets.length === 0 ? publicSubnets : privateSubnets;
    });
}
exports.computeWorkerSubnets = computeWorkerSubnets;
function getRouteTableAsync(parent, subnetId) {
    return __awaiter(this, void 0, void 0, function* () {
        const invokeOpts = { parent, async: true };
        try {
            // Attempt to get the explicit route table for this subnet. If there is no explicit rouute table for
            // this subnet, this call will throw.
            return yield aws.ec2.getRouteTable({ subnetId }, invokeOpts);
        }
        catch (_a) {
            // If we reach this point, the subnet may not have an explicitly associated route table. In this case
            // the subnet is associated with its VPC's main route table (see
            // https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html#RouteTables for details).
            const subnet = yield aws.ec2.getSubnet({ id: subnetId }, invokeOpts);
            const mainRouteTableInfo = yield aws.ec2.getRouteTables({
                vpcId: subnet.vpcId,
                filters: [
                    {
                        name: "association.main",
                        values: ["true"],
                    },
                ],
            }, invokeOpts);
            return yield aws.ec2.getRouteTable({ routeTableId: mainRouteTableInfo.ids[0] }, invokeOpts);
        }
    });
}
/**
 * Returns true if the given CIDR block falls within a private range [1].
 * [1] https://en.wikipedia.org/wiki/Private_network
 */
function isPrivateCIDRBlock(cidrBlock) {
    const privateA = new netmask.Netmask("10.0.0.0/8");
    const privateB = new netmask.Netmask("172.16.0.0/12");
    const privateC = new netmask.Netmask("192.168.0.0/16");
    return (privateA.contains(cidrBlock) || privateB.contains(cidrBlock) || privateC.contains(cidrBlock));
}
/**
 * Iterates through the tags map creating AWS ASG-style tags
 */
function tagsToAsgTags(tagsInput) {
    return pulumi.output(tagsInput).apply((tags) => {
        let output = "";
        for (const tag of Object.keys(tags)) {
            output += `
                          - Key: ${tag}
                            Value: ${tags[tag]}
                            PropagateAtLaunch: 'true'`;
        }
        return output;
    });
}
/**
 * ManagedNodeGroup is a component that wraps creating an AWS managed node group.
 *
 * See for more details:
 * https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html
 */
class ManagedNodeGroup extends pulumi.ComponentResource {
    /**
     * Create a new AWS managed node group.
     *
     * @param name The _unique_ name of this component.
     * @param args The arguments for this node group.
     * @param opts A bag of options that control this component's behavior.
     */
    constructor(name, args, opts) {
        super("eks:index:ManagedNodeGroup", name, args, opts);
        this.nodeGroup = createManagedNodeGroup(name, args, this, opts === null || opts === void 0 ? void 0 : opts.provider);
        this.registerOutputs(undefined);
    }
}
exports.ManagedNodeGroup = ManagedNodeGroup;
/**
 * This is a variant of `ManagedNodeGroup` that is used for the MLC `ManagedNodeGroup`. We don't just use
 * `ManagedNodeGroup`, because we need to accept `ClusterInternal` as the `cluster` arg, so we can correctly
 * pull out `cluster.core` for use in creating the `NodeGroupV2`.
 *
 * @internal
 */
class ManagedNodeGroupInternal extends pulumi.ComponentResource {
    constructor(name, args, opts) {
        const type = "eks:index:ManagedNodeGroup";
        if (opts === null || opts === void 0 ? void 0 : opts.urn) {
            const props = {
                nodeGroup: undefined,
            };
            super(type, name, props, opts);
            return;
        }
        super(type, name, args, opts);
        const core = pulumi
            .output(args.cluster)
            .apply((c) => (c instanceof cluster_1.ClusterInternal ? c.core : c));
        const group = createManagedNodeGroupInternal(name, args, core, this, opts === null || opts === void 0 ? void 0 : opts.provider);
        this.nodeGroup = pulumi.output(group);
        this.registerOutputs({
            nodeGroup: this.nodeGroup,
        });
    }
}
exports.ManagedNodeGroupInternal = ManagedNodeGroupInternal;
/**
 * Create an AWS managed node group.
 *
 * See for more details:
 * https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html
 */
function createManagedNodeGroup(name, args, parent, provider) {
    const core = args.cluster instanceof cluster_1.Cluster ? args.cluster.core : args.cluster;
    return createManagedNodeGroupInternal(name, args, pulumi.output(core), parent !== null && parent !== void 0 ? parent : core.cluster, provider);
}
exports.createManagedNodeGroup = createManagedNodeGroup;
function createManagedNodeGroupInternal(name, args, core, parent, provider) {
    // Compute the nodegroup role.
    if (!args.nodeRole && !args.nodeRoleArn) {
        // throw new pulumi.ResourceError(`An IAM role, or role ARN must be provided to create a managed node group`);
        throw new pulumi.ResourceError(`An IAM role, or role ARN must be provided to create a managed node group`, parent);
    }
    if (args.nodeRole && args.nodeRoleArn) {
        throw new pulumi.ResourceError("nodeRole and nodeRoleArn are mutually exclusive to create a managed node group", parent);
    }
    let roleArn;
    if (args.nodeRoleArn) {
        roleArn = args.nodeRoleArn;
    }
    else if (args.nodeRole) {
        roleArn = pulumi.output(args.nodeRole).apply((r) => r.arn);
    }
    else {
        throw new pulumi.ResourceError("The managed node group role provided is undefined", parent);
    }
    // Check that the nodegroup role has been set on the cluster to
    // ensure that the aws-auth configmap was properly formed.
    const nodegroupRole = pulumi.all([core.instanceRoles, roleArn]).apply(([roles, rArn]) => {
        // Map out the ARNs of all of the instanceRoles. Note that the roles array may be undefined if
        // unspecified by the Pulumi program.
        const roleArns = roles ? roles.map((role) => role.arn) : [];
        // Try finding the nodeRole in the ARNs array.
        return pulumi.all([roleArns, rArn]).apply(([arns, arn]) => {
            return arns.find((a) => a === arn);
        });
    });
    pulumi
        .all([core.cluster.accessConfig.authenticationMode, nodegroupRole])
        .apply(([authMode, role]) => {
        // access entries can be added out of band, so we don't require them to be set in the cluster.
        if (!(0, authenticationMode_1.supportsAccessEntries)(authMode) && !role) {
            throw new pulumi.ResourceError(`A managed node group cannot be created without first setting its role in the cluster's instanceRoles`, parent);
        }
    });
    // Compute the node group subnets to use.
    let subnetIds;
    if (args.subnetIds !== undefined) {
        subnetIds = pulumi.output(args.subnetIds);
    }
    else {
        subnetIds = core.apply((c) => {
            if (c.subnetIds !== undefined) {
                return c.subnetIds;
            }
            else if (c.privateSubnetIds !== undefined) {
                return c.privateSubnetIds;
            }
            else if (c.publicSubnetIds !== undefined) {
                return c.publicSubnetIds;
            }
            else {
                return [];
            }
        });
    }
    // Omit the cluster from the args.
    const nodeGroupArgs = Object.assign({}, args);
    if ("cluster" in nodeGroupArgs) {
        delete nodeGroupArgs.cluster;
    }
    // Create a custom launch template for the managed node group if the user specifies either kubeletExtraArgs or bootstrapExtraArgs.
    // If the user sepcifies a custom LaunchTemplate, we throw an error and suggest that the user include this in the launch template that they are providing.
    // If neither of these are provided, we can use the default launch template for managed node groups.
    if (args.launchTemplate &&
        (args.kubeletExtraArgs || args.bootstrapExtraArgs || args.enableIMDSv2)) {
        throw new pulumi.ResourceError("If you provide a custom launch template, you cannot provide kubeletExtraArgs, bootstrapExtraArgs or enableIMDSv2. Please include these in the launch template that you are providing.", parent);
    }
    let launchTemplate;
    if (args.kubeletExtraArgs || args.bootstrapExtraArgs || args.enableIMDSv2) {
        launchTemplate = createMNGCustomLaunchTemplate(name, args, core, parent, provider);
        // Disk size is specified in the launch template.
        delete nodeGroupArgs.diskSize;
    }
    if (launchTemplate === null || launchTemplate === void 0 ? void 0 : launchTemplate.imageId) {
        // EKS doesn't allow setting the kubernetes version in the node group if an image id is provided within the launch template.
        delete nodeGroupArgs.version;
    }
    // Make the aws-auth configmap a dependency of the node group.
    const ngDeps = core.apply((c) => (c.eksNodeAccess !== undefined ? [c.eksNodeAccess] : []));
    // Create the managed node group.
    const nodeGroup = new aws.eks.NodeGroup(name, Object.assign(Object.assign({}, nodeGroupArgs), { clusterName: args.clusterName || core.cluster.name, nodeRoleArn: roleArn, scalingConfig: pulumi.all([args.scalingConfig]).apply(([config]) => {
            var _a, _b, _c;
            const desiredSize = (_a = config === null || config === void 0 ? void 0 : config.desiredSize) !== null && _a !== void 0 ? _a : 2;
            const minSize = (_b = config === null || config === void 0 ? void 0 : config.minSize) !== null && _b !== void 0 ? _b : 1;
            const maxSize = (_c = config === null || config === void 0 ? void 0 : config.maxSize) !== null && _c !== void 0 ? _c : 2;
            return {
                desiredSize: desiredSize,
                minSize: minSize,
                maxSize: maxSize,
            };
        }), subnetIds: subnetIds, launchTemplate: launchTemplate
            ? {
                id: launchTemplate.id,
                version: launchTemplate.latestVersion.apply((version) => {
                    return `${version}`;
                }),
            }
            : args.launchTemplate }), { parent: parent, dependsOn: ngDeps, provider });
    return nodeGroup;
}
/**
 * Create a custom launch template for the managed node group if the user specifies either kubeletExtraArgs or bootstrapExtraArgs.
 */
function createMNGCustomLaunchTemplate(name, args, core, parent, provider) {
    let userData;
    // If the user specifies either kubeletExtraArgs or bootstrapExtraArgs, we need to create a base64 encoded user data script.
    if (args.kubeletExtraArgs || args.bootstrapExtraArgs) {
        const kubeletExtraArgs = args.kubeletExtraArgs ? args.kubeletExtraArgs.split(" ") : [];
        let bootstrapExtraArgs = args.bootstrapExtraArgs ? " " + args.bootstrapExtraArgs : "";
        if (kubeletExtraArgs.length === 1) {
            // For backward compatibility with previous versions of this package, don't wrap a single argument with `''`.
            bootstrapExtraArgs += ` --kubelet-extra-args ${kubeletExtraArgs[0]}`;
        }
        else if (kubeletExtraArgs.length > 1) {
            bootstrapExtraArgs += ` --kubelet-extra-args '${kubeletExtraArgs.join(" ")}'`;
        }
        const userdata = pulumi
            .all([
            core.cluster.name,
            core.cluster.endpoint,
            core.cluster.certificateAuthority.data,
            args.clusterName,
        ])
            .apply(([clusterName, clusterEndpoint, clusterCertAuthority, argsClusterName]) => {
            return `MIME-Version: 1.0
Content-Type: multipart/mixed; boundary="==MYBOUNDARY=="

--==MYBOUNDARY==
Content-Type: text/x-shellscript; charset="us-ascii"

#!/bin/bash

/etc/eks/bootstrap.sh --apiserver-endpoint "${clusterEndpoint}" --b64-cluster-ca "${clusterCertAuthority}" "${argsClusterName || clusterName}"${bootstrapExtraArgs}
--==MYBOUNDARY==--`;
        });
        // Encode the user data as base64.
        userData = pulumi
            .output(userdata)
            .apply((ud) => Buffer.from(ud, "utf-8").toString("base64"));
    }
    // If the user specifies enableIMDSv2, we need to set the metadata options in the launch template.
    const metadataOptions = args.enableIMDSv2
        ? { httpTokens: "required", httpPutResponseHopLimit: 2, httpEndpoint: "enabled" }
        : undefined;
    const blockDeviceMappings = args.diskSize
        ? [
            {
                // /dev/xvda is the default device name for the root volume on an Amazon Linux 2 & AL2023 instance.
                deviceName: "/dev/xvda",
                ebs: {
                    volumeSize: args.diskSize,
                },
            },
        ]
        : undefined;
    return new aws.ec2.LaunchTemplate(`${name}-launchTemplate`, {
        blockDeviceMappings,
        userData,
        metadataOptions,
        // We need to supply an imageId if userData is set, otherwise AWS will attempt to merge the user data which will result in
        // nodes failing to join the cluster.
        imageId: userData ? getRecommendedAMI(args, core.cluster.version, parent) : undefined,
    }, { parent, provider });
}
/**
 * getRecommendedAMI returns the recommended AMI to use for a given configuration
 * when none is provided by the user.
 *
 * See: https://docs.aws.amazon.com/eks/latest/userguide/retrieve-ami-id.html
 */
function getRecommendedAMI(args, k8sVersion, parent) {
    const gpu = "gpu" in args ? args.gpu : undefined;
    let instanceTypes;
    if ("instanceType" in args && args.instanceType) {
        instanceTypes = [args.instanceType];
    }
    else if ("instanceTypes" in args) {
        instanceTypes = args.instanceTypes;
    }
    const amiType = getAMIType(args.amiType, gpu, instanceTypes);
    // if specified use the version from the args, otherwise use the version from the cluster.
    const version = args.version ? args.version : k8sVersion;
    const amiID = pulumi.output([version, amiType]).apply(([version, type]) => {
        const parameterName = `/aws/service/eks/optimized-ami/${version}/${type}/recommended/image_id`;
        return pulumi.output(aws.ssm.getParameter({ name: parameterName }, { parent, async: true }))
            .value;
    });
    return amiID;
}
/**
 * ec2InstanceRegex is a regular expression that can be used to parse an EC2
 * instance type string into its component parts. The component parts are:
 * - family: The instance family (e.g., "c5")
 * - generation: The instance generation (e.g., "2")
 * - processor: The processor type (e.g., "g")
 * - additionalCapabilities: Additional capabilities (e.g., "n")
 * - size: The instance size (e.g., "large")
 * These parts result in a string of the form: `c52gn.large`
 */
const ec2InstanceRegex = /([a-z]+)([0-9]+)([a-z])?\-?([a-z]+)?\.([a-zA-Z0-9\-]+)/;
/**
 * isGravitonInstance returns true if the instance type is a Graviton instance.
 * We determine this by checking if the third character of the instance type is
 * a "g".
 *
 * See https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html.
 */
function isGravitonInstance(instanceType) {
    const match = instanceType.toString().match(ec2InstanceRegex);
    if (!match) {
        throw new pulumi.ResourceError(`Invalid EC2 instance type: ${instanceType}`, undefined);
    }
    const processorFamily = match[3];
    return processorFamily === "g";
}
exports.isGravitonInstance = isGravitonInstance;
/**
 * getAMIType returns the AMI type to use for the given configuration based on the
 * architecture of the instance type.
 */
function getAMIType(amiType, gpu, instanceTypes) {
    const architecture = pulumi.output(instanceTypes).apply((instanceTypes) => {
        return pulumi
            .all(instanceTypes !== null && instanceTypes !== void 0 ? instanceTypes : [])
            .apply((instanceTypes) => getArchitecture(instanceTypes));
    });
    return pulumi.all([amiType, gpu, architecture]).apply(([amiType, gpu, architecture]) => {
        if (amiType) {
            // Return the user-specified AMI type.
            return amiType;
        }
        if (gpu) {
            // Return the Amazon Linux 2 GPU AMI type.
            return "amazon-linux-2-gpu";
        }
        if (architecture === "arm64") {
            // Return the Amazon Linux 2 ARM64 AMI type.
            return "amazon-linux-2-arm64";
        }
        return "amazon-linux-2";
    });
}
/**
 * Determines the architecture based on the provided instance types. Defaults to "x86_64" if no instance types are provided.
 *
 * @param instanceTypes - An array of instance types.
 * @returns The architecture of the instance types, either "arm64" or "x86_64".
 * @throws {pulumi.ResourceError} If the provided instance types do not share a common architecture.
 */
function getArchitecture(instanceTypes) {
    let hasGravitonInstances = false;
    let hasX64Instances = false;
    instanceTypes.forEach((instanceType) => {
        if (isGravitonInstance(instanceType)) {
            hasGravitonInstances = true;
        }
        else {
            hasX64Instances = true;
        }
        if (hasGravitonInstances && hasX64Instances) {
            throw new pulumi.ResourceError("Cannot determine architecture of instance types. The provided instance types do not share a common architecture", undefined);
        }
    });
    return hasGravitonInstances ? "arm64" : "x86_64";
}
exports.getArchitecture = getArchitecture;
//# sourceMappingURL=nodegroup.js.map